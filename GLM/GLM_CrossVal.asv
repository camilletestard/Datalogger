function [Y_hat,Betas,CIs,Rsquared_per,LL_per,pvalues_per,problem_neurons] = GLM_CrossVal(X,Y,kfolds,is_smooth)
%GLM_CROSSVAL Custom code to run the cross validation on our glm data
%   Detailed explanation to come.  For now writing this since the built in
%   function for matlab doesn't seem particularly useful and the other
%   function we have from T and T 2022 makes certain assumptions about the
%   format of the data we don't want to deal with.  Designed to work with
%   any of our glm set ups

%INPUTS:
%X - design matrix for these models
%Y - ALL spiking data (will design function to loop over all neurons)
%kfolds - number of folds to use, scalar



%OUTPUTS:


%% Preallocate variables Set up cross validation

%Note: GLM fit also generates a coeff for the intercept term so have to add
%1 to all the size(X,2) things.
Betas = NaN(size(X,2)+1,size(Y,2)); %Average over CV Beta for each regressors (row) for each neuron (column)
CIs = NaN(size(X,2)+1,size(Y,2),2); %Average CI for each regressor, for each neuron, first page lower bound, second upper bound;
Rsquared_per = NaN(1,size(Y,2));%Average R^2 for EACH NEURON MODEL averaged over CV
%For now doing adjusted R^2, but can change this in the CV loop
LL_per = NaN(1,size(Y,2));
pvalues_per = NaN(size(X,2)+1,size(Y,2),kfolds);
Y_hat = NaN(size(Y)); %Prediction for all time points for each neuron, concatenated over CV

%rng(1) %For reproducability across runs




%Divide these into approximately kfolds groups (up to a rounding)
foldCnt = floor(size(Y,1)/kfolds);

%% Check each fold of the design matrix is full rank
%If not, keep redoing the permutaion until they are.

%Update 2022-08-30: It is clear that this won't work as it seems need over
%95% of the data to be in the fold to guarantee that the train design
%matrix is full rank.  For now, solve this by seeing what regressors they
%are.  Just read an article explaining Pillow's point about regularization
%though.  It can prevent rank issues by introducing an additional term that
%will change the approximately zero singular values in the matrix to a
%non-zero factor and allow for the Moore-Penrose Inverse.  See this link
%for quick details: https://calculatedcontent.com/2018/09/21/rank-collapse-in-deep-learning/
%Further update: Looks like even with NO delays variable 26 almost always
%caues an issue in at least one of the folds and sometimes variable 25
%does.  These are partner variables so maybe we can just do without for
%now?  These are groom partner which make sense to be redunant with getting
%groomed in subject and foraging which is a surprise but eh.

%Removing partner grooming subject did not fix overall problem (with the
%delays) but does seem like it may have fixed the problem when there are no
%delays.

if kfolds >1

    good = false;
    counter = 0;
    problem_reg = [];
    while ~good && counter <= 100
        counter = counter+1;
        display(['Making sure design matrid for all folds is full rank. Try #' num2str(counter)])
        randIdx = randperm(size(Y,1)); %Get randperm of indecies for whole session
        %Need to due permentation instead of just a partition since we have the
        %block design (i.e. don't want fits that are only block 1 or block 2)
        X_check = cell(1,kfolds);
        rank_check = false(1,kfolds);

        for iFolds = 1:kfolds
            dataIdx = true(1,size(Y,1)); %Start with using all of the session (i.e. all true indecies)


            dataIdx(randIdx(((iFolds - 1)*foldCnt) + (1:foldCnt))) = false;

            X_check{1,iFolds} = X(dataIdx,:); %Put the design matrix with these random inds into X_check
            
            %used qr check here to figure out which regressor is the issue
            %and see if it is consistent some subset of regressors
            rejReg = log_run_QR(X_check{iFolds},0);

            rank_check(iFolds) = ~any(rejReg); %Make sure that the subset matrix is full rank
            
            if ~rank_check(iFolds)
                
                problem_reg = [problem_reg find(rejReg)]; %Just keep appending to this vector than do a histogram after a set amount of tries.
                
            end

        end
        %find(rank_check == 0)%update it is not consistently one particular
        %fold, so nothing to fix there.  Often getting 90% of these good
        %though which is very annoying
        sum(rank_check)/kfolds
        good = all(rank_check); %If all are full rank, set good to true.  Otherwise redo loop

    end
    if counter >99
        the_info = histogram(problem_reg,'BinMethod','integers')
    end
end
%% Loop over each neuron

%Update 2022-08-29 might want to save more stuff than this, but I think
%this is okay for a first pass.
problem_neurons = false(1,size(Y,2));


for n = 1:size(Y,2) %First select neuron to use then do CV proceedure for each neuron separately.
%Update 2022-08-29 I think this will make the loop easier to manage
display(['Working on neuron #' num2str(n)])
Y_cur = Y(:,n); %Select neuron
cBeta = cell(3,kfolds); %One for the beta and one for each part of the confidence interval
cPvalues = NaN(size(X,2)+1,kfolds); %Save the P value for each coefficent for each fold.  Combine later with Fisher's method
cR2 = NaN(1,kfolds); %Save the R^2 value for each neurons fit.
cLL = NaN(1,kfolds); %Save the LL value for each neurons fit.
Y_cur_hat = NaN(size(Y_cur)); %Predicted fits that will be filled in with each fold.
lastwarn('','') %empty warning tracker before each model fit
% Run cross validation loop
    for iFolds = 1:kfolds
        display(['CV fold #' num2str(iFolds)])
        dataIdx = true(1,size(Y_cur,1)); %Start with using all of the session (i.e. all true indecies)
        
        if kfolds >1
        %Set the indecies of the TEST set in the fold to false
        %Only left with the training indecies as true
        dataIdx(randIdx(((iFolds - 1)*foldCnt) + (1:foldCnt))) = false;
        end
        
        if is_smooth %Use Gaussian 
        
            mdl = fitglm(X(dataIdx,:),Y_cur(dataIdx),'linear','Distribution','normal'); 
            warning_thrown = lastwarn;
        else %Use Poisson
            
            mdl = fitglm(X(dataIdx,:),Y_cur(dataIdx), 'linear','Distribution','poisson');
            warning_thrown = lastwarn; 
        end
        
        %Put results from each fold in a storage variable
        cBeta{1,iFolds} = mdl.Coefficients.Estimate; %Estimates of coefficents
        temp = mdl.coefCI;
        cBeta{2,iFolds} = temp(:,1); %In the second cell put the low confidence interval
        cBeta{3,iFolds} = temp(:,2); %In the third cell put the high confidence interval
        
        cPvalues(:,iFolds) = mdl.Coefficients.pValue; %P value for t-test of significance of coefficent
        cR2(1,iFolds) = mdl.Rsquared.Adjusted; %R squared value adjusted for dfe for each neuron and its data.
        cLL(1,iFolds) = mdl.LogLikelihood;% LL for this fit
        
        if kfolds>1
        Y_cur_hat(~dataIdx) = mdl.feval(X(~dataIdx,:)); %Predict from the data that WAS NOT in the training set.
        else
        Y_cur_hat = mdl.feval(X);
        end
    end
    %Check warning at the end, if not empty then indicate cell was a
    %problem cell.
    
    if ~isempty(warning_thrown)
        
        problem_neurons(n) = true;
        
    end
    
    %Collect results for this neuron across folds
    Betas(:,n) = mean(horzcat(cBeta{1,:}),2); %Take mean value across fold
    %Note when we add back actual folds this may not work and we may have
    %to turn this into a for loop or otherwise deal with it.
    CIs(:,n,1) = mean(horzcat(cBeta{2,:}),2);
    CIs(:,n,2) = mean(horzcat(cBeta{3,:}),2);
    
  
    
    pvalues_per(:,n) = mean(cPvalues,2);   %CHANGE THIS TO FISHERS METHOD!!!!!
    %USING AVERAGE FOR NOW FOR CONVENIENCE
    
    Rsquared_per(n) = mean(cR2,2);
    LL_per(n) = mean(cLL,2);
    Y_hat(:,n) = Y_cur_hat;
    
    
    
    
end
%% Results are collected sufficently above I think, so just put those as the output arguments.
end

